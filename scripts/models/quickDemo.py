#!/usr/bin/env python3
"""
Quick Demo of the Simple LSTM Bible-Quran Generative Model
Fast training and lightweight text generation.
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def lstm_quick_demo():
    """Quick demonstration of the LSTM model capabilities"""
    
    print("‚ö° SIMPLE LSTM BIBLE-QURAN GENERATIVE MODEL - QUICK DEMO")
    print("=" * 70)
    print()
    
    print("üöÄ What this LSTM model can do:")
    print("‚Ä¢ Train on 6000 religious texts from Bible and Quran")
    print("‚Ä¢ Generate text continuations in Spanish")
    print("‚Ä¢ Automatically determine optimal text length (20-100 tokens)")
    print("‚Ä¢ Use religious and spiritual language patterns")
    print("‚Ä¢ Train 10-20x faster than GPT-2")
    print()
    
    print("‚ö° LSTM ADVANTAGES over GPT-2:")
    print("‚Ä¢ Training time: ~5-10 minutes vs ~2-4 hours")
    print("‚Ä¢ Model size: ~1MB vs ~500MB")
    print("‚Ä¢ Memory usage: ~100MB vs ~2GB")
    print("‚Ä¢ Generation speed: Real-time vs slower")
    print("‚Ä¢ Resource requirements: CPU only vs GPU recommended")
    print()
    
    print("üéØ Example prompts that work well:")
    print("‚Ä¢ 'Dios es amor y misericordia'")
    print("‚Ä¢ 'La fe mueve monta√±as'")
    print("‚Ä¢ 'Bendito sea el nombre del Se√±or'")
    print("‚Ä¢ 'El amor de Dios es infinito'")
    print("‚Ä¢ 'La sabidur√≠a viene del cielo'")
    print()
    
    print("‚öôÔ∏è How to use:")
    print("1. Train the LSTM model (FAST!):")
    print("   python simpleLstmModel.py --mode train")
    print()
    print("2. Generate text interactively:")
    print("   python interactiveLstmGenerator.py")
    print()
    print("3. Generate from command line:")
    print("   python simpleLstmModel.py --mode generate --prompt 'Dios es amor' --tokens 50")
    print()
    
    print("üîß Technical details:")
    print("‚Ä¢ Architecture: 2-layer LSTM with embeddings")
    print("‚Ä¢ Vocabulary: Character-level (faster processing)")
    print("‚Ä¢ Dataset: 3342 clean religious texts")
    print("‚Ä¢ Language: Spanish religious/spiritual")
    print("‚Ä¢ Token range: 20-100 tokens")
    print("‚Ä¢ Memory usage: ~100MB")
    print("‚Ä¢ Training time: 5-10 minutes on CPU")
    print()
    
    print("üí° Pro tips:")
    print("‚Ä¢ Use religious/spiritual language for best results")
    print("‚Ä¢ Longer prompts get shorter, focused continuations")
    print("‚Ä¢ Shorter prompts get longer, creative continuations")
    print("‚Ä¢ Train for 10-15 epochs for good quality")
    print("‚Ä¢ Can retrain quickly if you want to improve")
    print()
    
    print("‚ö° SPEED COMPARISON:")
    print("-" * 30)
    print("GPT-2: 2-4 hours training, 500MB model")
    print("LSTM:  5-10 minutes training, 1MB model")
    print("Result: 20-50x faster training!")
    print()
    
    print("üéâ Ready to generate religious text FAST!")
    print("Start with: python simpleLstmModel.py --mode train")

if __name__ == "__main__":
    lstm_quick_demo()
