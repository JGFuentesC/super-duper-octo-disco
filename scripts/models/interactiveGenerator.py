#!/usr/bin/env python3
"""
Interactive Text Generator for Simple LSTM Bible-Quran Model
Fast and lightweight text generation interface.
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from generativeLanguageModel import SimpleLSTMTrainer

def main():
    """Interactive text generation interface for LSTM model"""
    
    print("="*60)
    print("SIMPLE LSTM BIBLE-QURAN GENERATIVE MODEL")
    print("="*60)
    print()
    
    # Check if model exists
    model_files = ['models/simple_lstm_model.pth', 'models/simple_lstm_tokenizer.pkl']
    if not all(os.path.exists(f) for f in model_files):
        print("âŒ No trained LSTM model found!")
        print("Please train the model first using:")
        print("python simpleLstmModel.py --mode train")
        print()
        return
    
    # Load the model
    print("ğŸ”„ Loading LSTM model...")
    try:
        trainer = SimpleLSTMTrainer()
        trainer.load_model('models/simple_lstm')
        print("âœ… LSTM model loaded successfully!")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return
    
    print()
    print("ğŸ’¡ Enter your text prompt and the LSTM model will continue it.")
    print("ğŸ’¡ Type 'quit' to exit.")
    print("ğŸ’¡ Type 'help' for usage tips.")
    print("ğŸ’¡ Type 'train' to retrain the model.")
    print()
    
    while True:
        try:
            # Get user input
            prompt = input("ğŸ“ Enter your prompt: ").strip()
            
            if prompt.lower() == 'quit':
                print("ğŸ‘‹ Goodbye!")
                break
            elif prompt.lower() == 'help':
                print_help()
                continue
            elif prompt.lower() == 'train':
                retrain_model()
                continue
            elif not prompt:
                print("âš ï¸  Please enter a valid prompt.")
                continue
            
            # Get number of tokens
            try:
                tokens_input = input("ğŸ”¢ Number of tokens to generate (20-100, default 50): ").strip()
                if tokens_input:
                    num_tokens = int(tokens_input)
                    if num_tokens < 20 or num_tokens > 100:
                        print("âš ï¸  Tokens must be between 20-100. Using default 50.")
                        num_tokens = 50
                else:
                    num_tokens = 50
            except ValueError:
                print("âš ï¸  Invalid number. Using default 50 tokens.")
                num_tokens = 50
            
            print()
            print("ğŸ”„ Generating text with LSTM...")
            print("-" * 40)
            
            # Generate text
            generated_text = trainer.predict_next_tokens(prompt, num_tokens)
            
            print()
            print("ğŸ¯ RESULT:")
            print("=" * 40)
            print(f"ğŸ“ Original prompt: {prompt}")
            print(f"ğŸš€ Generated continuation: {generated_text}")
            print("=" * 40)
            
            # Ask if user wants to continue
            print()
            continue_input = input("ğŸ”„ Generate another text? (y/n): ").strip().lower()
            if continue_input not in ['y', 'yes', 'sÃ­', 'si']:
                print("ğŸ‘‹ Goodbye!")
                break
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")
            print("Please try again.")

def print_help():
    """Print help information"""
    print()
    print("ğŸ“š USAGE TIPS:")
    print("-" * 30)
    print("â€¢ Write clear, specific prompts for better results")
    print("â€¢ Use religious or spiritual language for best performance")
    print("â€¢ Try prompts like:")
    print("  - 'Dios es amor y misericordia'")
    print("  - 'La fe mueve montaÃ±as'")
    print("  - 'Bendito sea el nombre del SeÃ±or'")
    print("â€¢ Adjust token count based on your needs:")
    print("  - 20-40 tokens: Short continuations")
    print("  - 50-70 tokens: Medium continuations")
    print("  - 80-100 tokens: Long continuations")
    print()
    print("âš¡ LSTM ADVANTAGES:")
    print("-" * 30)
    print("â€¢ Fast training (10-20x faster than GPT-2)")
    print("â€¢ Lightweight (~1MB vs ~500MB)")
    print("â€¢ Character-level generation")
    print("â€¢ Real-time text generation")
    print()

def retrain_model():
    """Retrain the LSTM model"""
    print("\nğŸ”„ RETRAINING LSTM MODEL")
    print("=" * 40)
    
    try:
        # Get training parameters
        epochs = input("Number of epochs (default 10): ").strip()
        epochs = int(epochs) if epochs else 10
        
        batch_size = input("Batch size (default 32): ").strip()
        batch_size = int(batch_size) if batch_size else 32
        
        lr = input("Learning rate (default 0.001): ").strip()
        lr = float(lr) if lr else 0.001
        
        print(f"\nTraining with: {epochs} epochs, batch_size={batch_size}, lr={lr}")
        
        # Initialize trainer and train
        trainer = SimpleLSTMTrainer()
        trainer.train(
            data_path='data/raw/coranBibliaCleanDataset.pkl',
            epochs=epochs,
            batch_size=batch_size,
            learning_rate=lr
        )
        
        print("âœ… Retraining completed!")
        
    except Exception as e:
        print(f"âŒ Error during retraining: {e}")
        print("Please try again.")

if __name__ == "__main__":
    main()
